{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Impoting necessary libararies"
      ],
      "metadata": {
        "id": "FHLgtDrTtcft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcVNCcpBsirp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input, Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Lambda, Dropout # Import Dropout here\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data from folders"
      ],
      "metadata": {
        "id": "_n4Zz81Ptkua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_folder(folder_path, label):\n",
        "    matrices = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.csv'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            df = pd.read_csv(file_path, skiprows=1, header=None)\n",
        "            df = df.iloc[:, 1:]\n",
        "            matrix = df.values.astype(np.float32)\n",
        "            matrices.append(matrix)\n",
        "            labels.append(label)\n",
        "    return np.array(matrices), np.array(labels)"
      ],
      "metadata": {
        "id": "iVLJZT4utbTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adhd_folder = \"/content/adhd\"\n",
        "control_folder = \"/content/control\"\n",
        "adhd_data, adhd_labels = load_data_from_folder(adhd_folder, label=1)\n",
        "control_data, control_labels = load_data_from_folder(control_folder, label=0)"
      ],
      "metadata": {
        "id": "nrTaskACtqfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining and splitting the data"
      ],
      "metadata": {
        "id": "ozi4Qntwt0Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([adhd_data, control_data])\n",
        "y = np.concatenate([adhd_labels, control_labels])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)\n"
      ],
      "metadata": {
        "id": "6Jt80FV_ty-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping the data"
      ],
      "metadata": {
        "id": "R8YK-POSuCfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 19, 19, 1)\n",
        "X_val = X_val.reshape(-1, 19, 19, 1)\n",
        "X_test = X_test.reshape(-1, 19, 19, 1)"
      ],
      "metadata": {
        "id": "X-Rf_llat7wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base network"
      ],
      "metadata": {
        "id": "Q6EHM6XcuICL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom"
      ],
      "metadata": {
        "id": "ViAVUgyJuBDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_base_network(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(RandomFlip(\"horizontal\"))\n",
        "    model.add(RandomRotation(0.2))\n",
        "    model.add(RandomZoom(0.2))\n",
        "    model.add(Conv2D(32, (5, 5), activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    # Additional layers for higher feature extraction capacity\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.6))\n",
        "    return model"
      ],
      "metadata": {
        "id": "AtMe7kHsuOWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (19, 19, 1)\n",
        "base_network = create_base_network(input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GHShB9AuRW4",
        "outputId": "5c9eb146-8c04-469e-83c8-f1fbbd54e08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining inputs to generate feature vectors"
      ],
      "metadata": {
        "id": "3_Rt3x8Cue4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "feat_vecs_a = base_network(input_a)\n",
        "feat_vecs_b = base_network(input_b)"
      ],
      "metadata": {
        "id": "eCqpprY0uWa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the distance between two features"
      ],
      "metadata": {
        "id": "pSmuwM5FuwHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distance = Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]), output_shape=(128,))([feat_vecs_a, feat_vecs_b])\n",
        "output = Dense(1, activation='sigmoid')(distance)\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "DonJj4yGu0z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Triplet Loss"
      ],
      "metadata": {
        "id": "CRbPnAr3vPze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def triplet_loss(margin):\n",
        "    def loss(y_true, y_pred):\n",
        "        anchor, positive, negative = y_pred[:, :128], y_pred[:, 128:256], y_pred[:, 256:]\n",
        "        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
        "        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
        "        loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n",
        "        return tf.reduce_mean(loss)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "E_2cjnRhu4FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Triplets for the Siamese Network"
      ],
      "metadata": {
        "id": "Z3slwHcSvX5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_triplets(X, y):\n",
        "    triplets = []\n",
        "    labels = []\n",
        "\n",
        "    n = min(len(X[y == 0]), len(X[y == 1]))\n",
        "    for i in range(n):\n",
        "        anchor = X[y == 0][i]\n",
        "        positive = X[y == 0][(i + 1) % n]\n",
        "\n",
        "        neg_index = np.random.choice(np.where(y == 1)[0])\n",
        "        negative = X[neg_index]\n",
        "\n",
        "        triplets.append([anchor, positive, negative])\n",
        "        labels.append(0)\n",
        "\n",
        "    return np.array(triplets), np.array(labels)"
      ],
      "metadata": {
        "id": "xdtHuf4ovUjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing training and validation triplets"
      ],
      "metadata": {
        "id": "gw_NgYPDvjSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_triplets, train_labels = create_triplets(X_train, y_train)\n",
        "val_triplets, val_labels = create_triplets(X_val, y_val)"
      ],
      "metadata": {
        "id": "bSeajipKvf8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the model using the base network for three inputs"
      ],
      "metadata": {
        "id": "HIltotgYvsTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (19, 19, 1)\n",
        "base_network = create_base_network(input_shape)\n",
        "\n",
        "input_anchor = Input(shape=input_shape)\n",
        "input_positive = Input(shape=input_shape)\n",
        "input_negative = Input(shape=input_shape)\n",
        "\n",
        "feat_vecs_anchor = base_network(input_anchor)\n",
        "feat_vecs_positive = base_network(input_positive)\n",
        "feat_vecs_negative = base_network(input_negative)"
      ],
      "metadata": {
        "id": "nokvJo-Lvm1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenating feature vectors for triplet loss calculation"
      ],
      "metadata": {
        "id": "IzAyWYnov1df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_output = tf.keras.layers.concatenate([feat_vecs_anchor, feat_vecs_positive, feat_vecs_negative], axis=1)"
      ],
      "metadata": {
        "id": "ULalQwNhvw4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining and compiling the model\n",
        "siamese_model = Model(inputs=[input_anchor, input_positive, input_negative], outputs=merged_output)\n",
        "siamese_model.compile(loss=triplet_loss(margin=0.8), optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Defining callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('siamese_model.keras', save_best_only=True, monitor='val_loss')"
      ],
      "metadata": {
        "id": "_fZNH3Mev6sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = siamese_model.fit(\n",
        "    [train_triplets[:, 0], train_triplets[:, 1], train_triplets[:, 2]], train_labels,\n",
        "    epochs=100,\n",
        "    batch_size=25,\n",
        "    validation_data=([val_triplets[:, 0], val_triplets[:, 1], val_triplets[:, 2]], val_labels),\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb5W3I_BwF1P",
        "outputId": "33e0be1c-79ad-439c-f827-2fd76e52d6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 434ms/step - accuracy: 0.0000e+00 - loss: 112.1931 - val_accuracy: 0.0000e+00 - val_loss: 0.7624\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.0000e+00 - loss: 116.7514 - val_accuracy: 0.0000e+00 - val_loss: 0.7616\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.0000e+00 - loss: 96.2832 - val_accuracy: 0.0000e+00 - val_loss: 0.7563\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.0000e+00 - loss: 84.9051 - val_accuracy: 0.0000e+00 - val_loss: 0.7484\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.0000e+00 - loss: 56.0571 - val_accuracy: 0.0000e+00 - val_loss: 0.7384\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.0000e+00 - loss: 65.4811 - val_accuracy: 0.0000e+00 - val_loss: 0.7338\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.0000e+00 - loss: 35.1172 - val_accuracy: 0.0000e+00 - val_loss: 0.7275\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.0000e+00 - loss: 40.3894 - val_accuracy: 0.0000e+00 - val_loss: 0.7202\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.0000e+00 - loss: 47.2131 - val_accuracy: 0.0000e+00 - val_loss: 0.7130\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.0000e+00 - loss: 19.5831 - val_accuracy: 0.0000e+00 - val_loss: 0.7032\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.0000e+00 - loss: 55.1472 - val_accuracy: 0.0000e+00 - val_loss: 0.6925\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.0000e+00 - loss: 34.5698 - val_accuracy: 0.0000e+00 - val_loss: 0.6813\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.0000e+00 - loss: 16.3279 - val_accuracy: 0.0000e+00 - val_loss: 0.6715\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.0000e+00 - loss: 30.3140 - val_accuracy: 0.0000e+00 - val_loss: 0.6591\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.0000e+00 - loss: 22.8599 - val_accuracy: 0.0000e+00 - val_loss: 0.6456\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.0000e+00 - loss: 19.2809 - val_accuracy: 0.0000e+00 - val_loss: 0.6343\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.0000e+00 - loss: 12.6116 - val_accuracy: 0.0000e+00 - val_loss: 0.6244\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.0000e+00 - loss: 14.5244 - val_accuracy: 0.0000e+00 - val_loss: 0.6145\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.0000e+00 - loss: 9.4003 - val_accuracy: 0.0000e+00 - val_loss: 0.6059\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.0000e+00 - loss: 10.1549 - val_accuracy: 0.0000e+00 - val_loss: 0.6019\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.0000e+00 - loss: 7.0253 - val_accuracy: 0.0000e+00 - val_loss: 0.5973\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.0000e+00 - loss: 8.0657 - val_accuracy: 0.0000e+00 - val_loss: 0.5922\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.0000e+00 - loss: 7.6416 - val_accuracy: 0.0000e+00 - val_loss: 0.5956\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0000e+00 - loss: 4.5428 - val_accuracy: 0.0000e+00 - val_loss: 0.6000\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.0000e+00 - loss: 5.5556 - val_accuracy: 0.0000e+00 - val_loss: 0.6068\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.0000e+00 - loss: 6.2096 - val_accuracy: 0.0000e+00 - val_loss: 0.6172\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.0000e+00 - loss: 3.7614 - val_accuracy: 0.0000e+00 - val_loss: 0.6275\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0000e+00 - loss: 4.1424 - val_accuracy: 0.0000e+00 - val_loss: 0.6344\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0000e+00 - loss: 4.0601 - val_accuracy: 0.0000e+00 - val_loss: 0.6415\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.0000e+00 - loss: 3.2370 - val_accuracy: 0.0000e+00 - val_loss: 0.6491\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.0000e+00 - loss: 2.6315 - val_accuracy: 0.0000e+00 - val_loss: 0.6533\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.0000e+00 - loss: 2.2026 - val_accuracy: 0.0000e+00 - val_loss: 0.6522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
      ],
      "metadata": {
        "id": "eC2S_ZM9wJAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compute distances"
      ],
      "metadata": {
        "id": "zJnwxny1wohV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_distances(anchor, positive, negative):\n",
        "    pos_dist = np.sum(np.square(anchor - positive), axis=1)\n",
        "    neg_dist = np.sum(np.square(anchor - negative), axis=1)\n",
        "    return pos_dist, neg_dist"
      ],
      "metadata": {
        "id": "GHw-N1vNwmaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing test triplets to make predictions"
      ],
      "metadata": {
        "id": "Y23b5OtWwxrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_triplets, test_labels = create_triplets(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "o136DJ-_wuiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting embeddings for all samples at once"
      ],
      "metadata": {
        "id": "3kYrntcjw_d1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = siamese_model.predict([test_triplets[:, 0], test_triplets[:, 1], test_triplets[:, 2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCQFHV3Nw4sH",
        "outputId": "e0f3b2dd-6b09-4932-aa58-f68706c99017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting the embeddings into anchor, positive, and negative"
      ],
      "metadata": {
        "id": "MMGv3SbfxKmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "anchor_embeddings = embeddings[:, :128]\n",
        "positive_embeddings = embeddings[:, 128:256]\n",
        "negative_embeddings = embeddings[:, 256:]\n"
      ],
      "metadata": {
        "id": "7BlcwEeXw-7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the distances"
      ],
      "metadata": {
        "id": "O4FEW2hDxOsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_dist, neg_dist = compute_distances(anchor_embeddings, positive_embeddings, negative_embeddings)\n"
      ],
      "metadata": {
        "id": "H1nFRYJbxJbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determining predictions based on distances"
      ],
      "metadata": {
        "id": "Ua5DvKlixajO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (pos_dist < neg_dist).astype(int)"
      ],
      "metadata": {
        "id": "yycpLHehxU7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(test_labels, y_pred))\n",
        "print(np.concatenate((test_labels.reshape(-1, 1), y_pred.reshape(-1,1)), axis=1))\n",
        "print(confusion_matrix(test_labels, y_pred))\n",
        "print(classification_report(test_labels, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLclf2wzxaK7",
        "outputId": "fc4d8586-f880-4b2c-8135-3f6c8a92bff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]]\n",
            "[[6 6]\n",
            " [0 0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67        12\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.50      0.25      0.33        12\n",
            "weighted avg       1.00      0.50      0.67        12\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SVeQPJKIyFkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}