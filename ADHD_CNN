# -*- coding: utf-8 -*-
"""adhd_cnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t0KLhezfx9bIkPXH92EUZ3zU7thEGb0y

Step 1: Data Preparation

Normalize the Data
"""

import os #os dependent funct like reading and writing into the file
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler # used to normalize the features [0 1]
from sklearn.model_selection import train_test_split

adhd_folder = "/content/ADHD_MI"
control_folder = "/content/Control_MI"

# Function to load data from a folder
def load_data_from_folder(folder_path, label):
    matrices = []
    labels = []

    for filename in os.listdir(folder_path):
        if filename.endswith('.csv'):
            file_path = os.path.join(folder_path, filename)
            # Load the CSV file, skip the first row, and set the header to None
            df = pd.read_csv(file_path, skiprows=1, header=None)
            # Remove the first column
            df = df.iloc[:, 1:]
            # Get the 19*19 matrix
            matrix = df.values.astype(np.float32)
            matrices.append(matrix)
            labels.append(label)

    return np.array(matrices), np.array(labels)

# Load data
X_adhd, y_adhd = load_data_from_folder(adhd_folder, 1)  # 1 for ADHD
X_control, y_control = load_data_from_folder(control_folder, 0)  # 0 for control

# Combine data
X = np.concatenate((X_adhd, X_control), axis=0)
y = np.concatenate((y_adhd, y_control), axis=0)

# Step 1: Normalize the data
scaler = MinMaxScaler()

# Reshape to a 2D array for scaling, then back to 3D
X_scaled = scaler.fit_transform(X.reshape(-1, 19 * 19)).reshape(-1, 19, 19)


# Step 2: Add a channel dimension for CNN input
X_reshaped = X_scaled.reshape(-1, 19, 19, 1)  # Shape: (num_samples, 19, 19, 1)

"""Split the Data"""

# Step 3: Split the data into train, validation, and test sets
X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)

# Step 4: Print data shapes to verify
print(f"Training data shape: {X_train.shape}")
print(f"Validation data shape: {X_val.shape}")
print(f"Test data shape: {X_test.shape}")
print(f"Training labels shape: {y_train.shape}")
print(f"Validation labels shape: {y_val.shape}")
print(f"Test labels shape: {y_test.shape}")

""" Building the CNN Model"""

import tensorflow as tf
from tensorflow.keras.models import Sequential # used to build a network model layer by layer
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

model = Sequential()

# Convolutional Layer 1
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(19, 19, 1))) #size of matrix
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

# Convolutional Layer 2
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

# Flatten the output
model.add(Flatten())

# Fully Connected Layer
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))

# Output Layer
model.add(Dense(1, activation='sigmoid'))  # For binary classification

"""compile the model"""

model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

"""Training the Model"""

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_cnn_model.keras', save_best_only=True) # Changed the file extension to .keras

history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=16,
    validation_data=(X_val, y_val),
    callbacks=[early_stopping, model_checkpoint]
)

model.load_weights('best_cnn_model.keras')

"""Evaluating the Model"""

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {test_accuracy:.2f}')

from sklearn.metrics import classification_report

y_pred = (model.predict(X_test) > 0.5).astype("int32")
y_pred = y_pred.reshape(-1) # Reshape y_pred to be a 1D array
print(np.concatenate((y_test.reshape(-1, 1), y_pred.reshape(-1,1)), axis=1))
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt

# Plot accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

# Plot loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()